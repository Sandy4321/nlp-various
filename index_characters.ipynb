{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import NLTK and sentence tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in text and create a list of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = ' '.join(open('./text.txt').readlines())\n",
    "charactes = ['Jean Valjean', 'Javert', 'Fantine', 'Cosette', 'Marius Pontmercy', 'Éponine', \n",
    "             'Monsieur Thénardier ', 'Madame Thénardier', 'Enjolras', 'Gavroche', 'Bishop Myriel', 'Grantaire' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize sentences and calculate the number of sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sents: 35645\n",
      "About the epoch of the coronation, some petty affair connected with\n",
      " his curacy--just what, is not precisely known--took him to Paris.\n"
     ]
    }
   ],
   "source": [
    "sentences = sent_tokenize(text)\n",
    "print('# sents:', len(sentences))\n",
    "print(sentences[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary which store id's of sentences where a character occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "character2sentence = {}\n",
    "for ch in charactes:\n",
    "    character2sentence[ch] = []\n",
    "    for i in range(len(sentences)):\n",
    "        if ch in sentences[i]:\n",
    "            character2sentence[ch].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3217, 3218, 3220, 3246, 3250, 3252, 3257, 3258, 3264, 3267, 3269, 3276, 3295, 3329, 3338, 3346, 3349, 3350, 3355, 3359, 3364, 3369, 3394, 3450, 3608, 3609, 3611, 3664, 3721, 3722, 3735, 3740, 3754, 3759, 3771, 3772, 3823, 3885, 3886, 3894, 3895, 3900, 3902, 3914, 3920, 3923, 4115, 4117, 4122, 4521, 4525, 4526, 4535, 4553, 4561, 4577, 4579, 4584, 4598, 4600, 4612, 4615, 4631, 4645, 4657, 4675, 4678, 4709, 4712, 4715, 4719, 4722, 4737, 4752, 4754, 4761, 4762, 4764, 4765, 4775, 4783, 4809, 4814, 4827, 4869, 4881, 4884, 4903, 4960, 4974, 4977, 4988, 5024, 5025, 5054, 5056, 5085, 5095, 5121, 5130, 5135, 5139, 5145, 5153, 5167, 5183, 5188, 5209, 5217, 5233, 5246, 5250, 5509, 5510, 5550, 5551, 5552, 5553, 5558, 5559, 5742, 5905, 5909, 6466, 6475, 6483, 6486, 6487, 6492, 6494, 6503, 6507, 6527, 6531, 6534, 6541, 6544, 6551, 6552, 6553, 6561, 6587, 6591, 6594, 6600, 6768, 7138, 7148, 7179, 7209, 7276, 7277, 7286, 7294, 7299, 7317, 7320, 7323, 7330, 7355, 7356, 7361, 7382, 7386, 7398, 7399, 7413, 7439, 7453, 7457, 7467, 7471, 7474, 7481, 7482, 7484, 7486, 7525, 7620, 7622, 7626, 7627, 7629, 10430, 10457, 10714, 11430, 11447, 11449, 11456, 19212, 21442, 21449, 21452, 21454, 21457, 22308, 34616, 35271, 35272]\n"
     ]
    }
   ],
   "source": [
    "print(character2sentence['Fantine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary which maps sentence id to chapter id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent2chapter = {}\n",
    "cur_ch = 0 \n",
    "for i in range(len(sentences)):\n",
    "    if 'CHAPTER' in sentences[i]:\n",
    "        cur_ch += 1\n",
    "    sent2chapter[i] = cur_ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary which store id's of chapters where a character occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "character2chapter = {}\n",
    "for ch in charactes:\n",
    "    character2chapter[ch] = list(set([sent2chapter[i] for i in character2sentence[ch]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29, 30, 31, 33, 34, 35, 36, 37, 40, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 60, 62, 66, 67, 68, 69, 70, 220, 102, 106, 363, 236, 364, 245, 118]\n"
     ]
    }
   ],
   "source": [
    "print(character2chapter['Fantine'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
